1. Write code to implement bagged decision trees and random forests. Compare the performance of these methods with plain decision trees on the handwritten digit recognition problem (you can read more about the data set at http://amlbook.com/data/zip/zip.info). Focus on two specific problems: distinguishing between the digit one vs. the digit three, and distinguishing between the digit three vs. the digit five.
2. Write code to implement AdaBoost using decision stumps as the weak learners (use the fitctree function to implement the weak learners). Again, focus on the one-vs-three and three-vs-five problems (as described in 1) using zip_train.csv and zip_test.csv.
