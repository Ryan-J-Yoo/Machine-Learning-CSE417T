Learn a logistic regression model on the data in cleveland_train.csv; note that the labels in the data set are 0/1 so you will need to convert those to -1/+1 in order to ensure that everything we’ve done in class is still valid). Use a learning rate of η0 = 10−5 and automatically terminate if the magnitude of every element of the gradient is less than 10−3. Initialize the weight vector to a vector of all zeros. Train the model three times with a different bound on the maximum number of iterations each time: 104, 105 and 106 (note that the termination condition based on the magnitude of the gradient still applies). Use each model to classify the data (using a cutoff probability of 0.5) in cleveland_test.csv.
